---
title: "Week4_Peer_Graded"
author: "Jayant"
date: "10/21/2020"
output: html_document
---

This is the week 4 final course project of the practical machine learning also in this I will be using rstudio markdown and knitr. proceeding for the analysis

Introduction of the project

we have collected huge databases from the Nike band, Fitbit, jawbone, and we will be utilizing those data for our analysis in this peer grade assignment.

So in this project, with the data from the accelerometer measure. of the individuals of their different-different class of physical activity

with the help of data, we will be predicting whether the individual is doing the exercises properly or not and the two files comprise of the test and training data, and from this, we will also predict the numbering of exercise like the 
order of them basically

firstly we will load the data and then proceed for the processing of the data and then we will do the exploratory analysis and then prediction for which model to select and then finally for the predicting of the o/p of the testing set


```{r}
library(caret)
library(knitr)

library(data.table)
library(rpart.plot)
library(rpart)

library(gbm)
library(ggplot2)

library(corrplot)

```
Now we will take the data and do the cleaning and then exploring the data. 

```{r}
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
traUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

test_this_data <- read.csv(url(testUrl))
tra_this_data <- read.csv(url(traUrl))


```
now proceeding for the cleaning the input of the data

```{r}
this_is_training_data <- tra_this_data[, colSums(is.na(tra_this_data)) == 0]
this_is_testing_data <- test_this_data[, colSums(is.na(test_this_data)) == 0]
```
now we will prepare the data for pred. in which we will consider seventy percentage of the data for the training set and rest of the thirty percentage of the data for the testing data set
and this_is_testing_data will be used furthuer again for the prediction of the 20 of the cases 

```{r}
this_is_training_data <- this_is_training_data[, -c(1:7)]
this_is_testing_data <- this_is_testing_data[, -c(1:7)]
dim(this_is_training_data)
```

```{r}
set.seed(1234)
datatraining <- createDataPartition(tra_this_data$classe, p = 0.7, list = FALSE)
this_is_training_data <- this_is_training_data[datatraining, ]
this_is_testing_data <- this_is_training_data[-datatraining, ]
dim(this_is_training_data)
dim(this_is_testing_data)
```
now we will be removing the variables that are non zero from the data gives
```{r}
noneZero <- nearZeroVar(this_is_training_data)
this_is_training_data <- this_is_training_data[, -noneZero]
this_is_testing_data <- this_is_testing_data[, -noneZero]
dim(this_is_training_data)
dim(this_is_testing_data)
```


```{r}
plot_cor <- cor(this_is_training_data[, -53])
corrplot(plot_cor, order = "FPC", method = "color", type = "upper", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
```

now in this as we can see that the corr. predic. are the ones with the dark colour intersec.

now we will be proceeding for the model building and for this we will use 2 different types of algorithms , trees and random forests for the prediction part 

```{r}
set.seed(20000)
tredec <- rpart(classe ~ ., data=this_is_training_data, method = "class")
rpart.plot(tredec)
```

now we will be validate the model 
```{r}
modelpre <- predict(tredec, this_is_testing_data, type = "class")
ab <- confusionMatrix(modelpre, this_is_testing_data$classe)
ab
```

```{r}
plot(modelpre)
```

now for the last part we will apply two models one by one 
the first one will be general boosted model and then the second one will be gbm model for this 
```{r}
set.seed(10000)
ctr_gbm <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
valid_gbm <- train(classe ~ .,data=this_is_training_data, method = "gbm", trControl = ctr_gbm, verbose = FALSE)
valid_gbm$finalModel
```

